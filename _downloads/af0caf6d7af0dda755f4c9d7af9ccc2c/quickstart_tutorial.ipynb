{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fleaaron/Pytorch-tutorials/blob/main/_downloads/af0caf6d7af0dda755f4c9d7af9ccc2c/quickstart_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gYWLbkMqd24A"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggd4lr93d24D"
      },
      "source": [
        "[Learn the Basics](intro.html) \\|\\| **Quickstart** \\|\\|\n",
        "[Tensors](tensorqs_tutorial.html) \\|\\| [Datasets &\n",
        "DataLoaders](data_tutorial.html) \\|\\|\n",
        "[Transforms](transforms_tutorial.html) \\|\\| [Build\n",
        "Model](buildmodel_tutorial.html) \\|\\|\n",
        "[Autograd](autogradqs_tutorial.html) \\|\\|\n",
        "[Optimization](optimization_tutorial.html) \\|\\| [Save & Load\n",
        "Model](saveloadrun_tutorial.html)\n",
        "\n",
        "Quickstart\n",
        "==========\n",
        "\n",
        "This section runs through the API for common tasks in machine learning.\n",
        "Refer to the links in each section to dive deeper.\n",
        "\n",
        "Working with data\n",
        "-----------------\n",
        "\n",
        "PyTorch has two [primitives to work with\n",
        "data](https://pytorch.org/docs/stable/data.html):\n",
        "`torch.utils.data.DataLoader` and `torch.utils.data.Dataset`. `Dataset`\n",
        "stores the samples and their corresponding labels, and `DataLoader`\n",
        "wraps an iterable around the `Dataset`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "weQlF-nEd24E"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIOENPRzd24F"
      },
      "source": [
        "PyTorch offers domain-specific libraries such as\n",
        "[TorchText](https://pytorch.org/text/stable/index.html),\n",
        "[TorchVision](https://pytorch.org/vision/stable/index.html), and\n",
        "[TorchAudio](https://pytorch.org/audio/stable/index.html), all of which\n",
        "include datasets. For this tutorial, we will be using a TorchVision\n",
        "dataset.\n",
        "\n",
        "The `torchvision.datasets` module contains `Dataset` objects for many\n",
        "real-world vision data like CIFAR, COCO ([full list\n",
        "here](https://pytorch.org/vision/stable/datasets.html)). In this\n",
        "tutorial, we use the FashionMNIST dataset. Every TorchVision `Dataset`\n",
        "includes two arguments: `transform` and `target_transform` to modify the\n",
        "samples and labels respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "98berDFPd24F",
        "outputId": "c922670c-123f-4a2b-e195-6cf9b709520b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 17.7MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 301kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 4.96MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 12.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(training_data.data[523], cmap = 'gray')"
      ],
      "metadata": {
        "id": "2sZ8FgU4evld",
        "outputId": "c05fc4a4-f640-46e0-c828-526bb19e9e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x786f14dd9850>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7-BwTtxd24G"
      },
      "source": [
        "We pass the `Dataset` as an argument to `DataLoader`. This wraps an\n",
        "iterable over our dataset, and supports automatic batching, sampling,\n",
        "shuffling and multiprocess data loading. Here we define a batch size of\n",
        "64, i.e. each element in the dataloader iterable will return a batch of\n",
        "64 features and labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OYyBzMQ3d24G",
        "outputId": "cb212de0-20f7-4508-f969-c122ef7f7b6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QNhGcrZd24G"
      },
      "source": [
        "Read more about [loading data in PyTorch](data_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-YSBJi-d24H"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUbX2rxNd24H"
      },
      "source": [
        "Creating Models\n",
        "===============\n",
        "\n",
        "To define a neural network in PyTorch, we create a class that inherits\n",
        "from\n",
        "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
        "We define the layers of the network in the `__init__` function and\n",
        "specify how data will pass through the network in the `forward`\n",
        "function. To accelerate operations in the neural network, we move it to\n",
        "the\n",
        "[accelerator](https://pytorch.org/docs/stable/torch.html#accelerators)\n",
        "such as CUDA, MPS, MTIA, or XPU. If the current accelerator is\n",
        "available, we will use it. Otherwise, we use the CPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dHvcU-ZOd24H",
        "outputId": "2c72548c-ce16-4232-fb91-4ab9636e0db1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.Tensor([[20,33, 43],\n",
        "                  [8, 97, 75],\n",
        "                  [12, 32, 86]])\n",
        "\n",
        "print(a)\n",
        "a = torch.flatten(a)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "Yb0N5VbcgiGi",
        "outputId": "28992db3-e336-4e52-b4ef-aa81a2136d13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[20., 33., 43.],\n",
            "        [ 8., 97., 75.],\n",
            "        [12., 32., 86.]])\n",
            "tensor([20., 33., 43.,  8., 97., 75., 12., 32., 86.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6n9OD1Nd24I"
      },
      "source": [
        "Read more about [building neural networks in\n",
        "PyTorch](buildmodel_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvgxANbXd24I"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzW3evCLd24I"
      },
      "source": [
        "Optimizing the Model Parameters\n",
        "===============================\n",
        "\n",
        "To train a model, we need a [loss\n",
        "function](https://pytorch.org/docs/stable/nn.html#loss-functions) and an\n",
        "[optimizer](https://pytorch.org/docs/stable/optim.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UuU3CFvSd24I"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZGTdyndd24I"
      },
      "source": [
        "In a single training loop, the model makes predictions on the training\n",
        "dataset (fed to it in batches), and backpropagates the prediction error\n",
        "to adjust the model\\'s parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwnK_De3d24I"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BORYiqD5d24I"
      },
      "source": [
        "We also check the model\\'s performance against the test dataset to\n",
        "ensure it is learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrDw0IfHd24J"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW2U8fz2d24J"
      },
      "source": [
        "The training process is conducted over several iterations (*epochs*).\n",
        "During each epoch, the model learns parameters to make better\n",
        "predictions. We print the model\\'s accuracy and loss at each epoch;\n",
        "we\\'d like to see the accuracy increase and the loss decrease with every\n",
        "epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYrfHYnFd24J"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu1gXAO3d24J"
      },
      "source": [
        "Read more about [Training your model](optimization_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKFapOhed24J"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m7z7URnd24J"
      },
      "source": [
        "Saving Models\n",
        "=============\n",
        "\n",
        "A common way to save a model is to serialize the internal state\n",
        "dictionary (containing the model parameters).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ry5-WBDpd24J"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kbqz8jCd24J"
      },
      "source": [
        "Loading Models\n",
        "==============\n",
        "\n",
        "The process for loading a model includes re-creating the model structure\n",
        "and loading the state dictionary into it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrWKkDk-d24J"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fM0d1AKd24K"
      },
      "source": [
        "This model can now be used to make predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRlRpSUQd24K"
      },
      "outputs": [],
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diwh8kDjd24K"
      },
      "source": [
        "Read more about [Saving & Loading your\n",
        "model](saveloadrun_tutorial.html).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}